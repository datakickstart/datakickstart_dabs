name: Deploy simple_project to STAGING

concurrency: 1

on:
  workflow_dispatch:

  push:
    branches:
      - main
    paths:
      - "**/*.yml"
      - "**/*.py"

jobs:
  deploy:
    name: "Deploy bundle"
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./simple_project

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - run: python -m pip install --upgrade pip
      - run: pip install wheel
      - run: pip3 install wheel
      - run: pip install -r requirements.txt

      - name: Run unit tests
        env:
          SPARK_REMOTE: ${{secrets.SPARK_REMOTE}}   
        run: |
          pytest tests/
      
      - uses: databricks/setup-cli@main

      - run: databricks bundle deploy -t staging
        env:
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_BUNDLE_ENV: staging

  pipeline_update:
    name: "Run pipeline update"
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./simple_project

    needs:
      - deploy

    steps:
      - uses: actions/checkout@v3

#       - uses: actions/setup-python@v4
#         with:
#           python-version: 3.11
#           cache: 'pip'

#       - run: pip install -r requirements.txt
#         working-directory: .github/support

      - uses: databricks/setup-cli@main

      - shell: bash
        name: Run e2e test workflow
        run: |
          set -o pipefail
          databricks bundle run notebook_validation_job -t staging --refresh-all 2>&1 | tee output.log
        env:
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_BUNDLE_ENV: staging